---
title: "Churn Prediction "
author: "Le Thi Thanh Tam"
date: "9/1/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Objective

Case : Which customers are likely to churn ?

* **Customer Churn** occurs when customers leave/stop doing business with the company or service.
* The ability to predict when a customer is at a high risk of churning is valuable for every business with returning customers. Churn is defined as the number of customers cancelling within a time period divided by the number of active customers at the start of that period. In order to apply a modeling technique to predict churn, we need to understand the customer behavior and characteristics which signal the risk of customers churn.

* For this analytics, I will look into a bank customer data to predict whether the customer will leave the credit card services of the bank. 

* I will use R for this project. The number of data is not too large so can use R directly. (R is one of the predominant languages in data science ecosystem and makes it simple to efficiently implement statistical techniques and thus it is excellent choice for machine learning tasks).


## Model 

**Classification Problem**

First I transformed some categorical variable into numeric ( i.e income) and readable code. I also split the data into train and tests sets with a test size of 20%. I tried two different models and evaluated the accuracy based on the test error rate

* **Logistic Regression** the small p-values associated with almost all of the predictors

* However **RandomForest** with the lower test error rate

```{r message=FALSE, warning=FALSE, results='hide'}
# load data
churn <- read.csv("E:/ThanhTam_DA/Project/Prediction/Bank Churners/churn.csv")
churn$X = NULL # Drop the first index column
```

* Before starting I transformed the type for each column.

  * Change the values of Attrition Flag, Gender, Marital Status as factor, the category Income into Numeric 

```{r message=FALSE, warning=FALSE, results='hide'}
# Transformation type
churn$Attrition_Flag = as.factor(churn$Attrition_Flag)
churn$Gender = as.factor(churn$Gender)
churn$Marital_Status = as.factor(churn$Marital_Status)

# Convert income category into numberic 
churn$Income = rep('', nrow(churn))
churn$Income[churn$Income_Category == 9] = 0
churn$Income[churn$Income_Category == 1] = 40000/2
churn$Income[churn$Income_Category == 2] = (40000+60000)/2
churn$Income[churn$Income_Category == 3] = (60000+80000)/2
churn$Income[churn$Income_Category == 4] = (80000+120000)/2
churn$Income[churn$Income_Category == 5] = 120000
is.factor(churn$Attrition_Flag)

churn$Income = as.numeric(churn$Income)
is.numeric(churn$Income)
churn$Income_Category = NULL
summary(churn)
```


```{r message=FALSE, warning=FALSE, results='hide' }
# create a new data frame not include unknown values _ Remove unknown`
churn2 <- churn[!(churn$Marital_Status == 9|churn$Education_Level == 99),]
summary(churn2)
attach(churn2)
```


### 1. Logistic Regression

```{r message=FALSE, warning=FALSE}
glm.fits = glm(Attrition_Flag~., churn2, family = binomial)
summary(glm.fits)
```

Some findings from glm :
* **Gender1** has small p-value means it is associated with our target. The negative coefficient for this predictor suggests **Male** is less likely to churn. 
* **Income** has a positive relationship with the churn likelihood.
* Person made **The total transaction amount** large tended to not churned . etc


#### Better assess the accuracy of the logistic regression model

* First split data into training and test sets

* Fit a logistic regression model on train data set

* Predict probabilities of churn customers on test set

* Compute the predictions and compare them to the actual churn customers

* test error rate equal 11%
```{r message=FALSE, warning=FALSE, results='hide'}
# first split data into training and test sets
set.seed(1)
train_set=sample(nrow(churn2), 0.8*nrow(churn2), replace = FALSE) # 80% dataset is the train set
train = churn2[train_set,]
test = churn2[-train_set,]

# fit a logistic regression model on train data set
glm.fits = glm(Attrition_Flag~.,data=train, family = binomial)

# predict probabilities of churn customers on test set
glm.probs=predict(glm.fits,test,type='response')

# compute the predictions and compare them to the actual churn customers
glm.pred=rep("0",nrow(test))
glm.pred[glm.probs>.5]="1"
table(glm.pred,test$Attrition_Flag)
(1316+104)/nrow(test)

#--> test error rate equal 100-89 is 11% !!!!
```

* We recall that the logistic regression model, the small p-values associted with almost all of the predictors. 

* In theory, consider the distribution of the predictors X (EDA part) is approximately normal in each of the classes, the logistic regression model may be unstable.

* Therefore we will consider to obtain better model for this project

### RandomForest

```{r message=FALSE, warning=FALSE, results='hide'}
library(randomForest)
set.seed(1)
rf.churn=randomForest(Attrition_Flag~., train, importance=TRUE)

yhat.rf= predict(rf.churn, newdata = test, type = "class")
table(yhat.rf,test$Attrition_Flag)
(1329+177)/nrow(test)
# mean(yhat.rf == test$Attrition_Flag)
#--> The classification accuracy of the model on the test set is 94.4% , test error rate is 5.6%
```

* The classification accuracy of the model on the test set is 94.4% , test error rate is 5.6%

**After developing the model, the model is applied to all customers such that we obtain the likelihood of churning for each customer. Ranking the results gives you the top X customers who are about to churn.**

